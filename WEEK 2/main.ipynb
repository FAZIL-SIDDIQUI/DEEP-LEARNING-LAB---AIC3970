{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b847ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights:\n",
      "W1 (input -> hidden1):\n",
      "[[-0.01724918 -0.00562288 -0.01012831  0.00314247 -0.00908024 -0.01412304\n",
      "   0.01465649 -0.00225776]\n",
      " [ 0.00067528 -0.01424748 -0.00544383  0.00110923 -0.01150994  0.00375698\n",
      "  -0.00600639 -0.00291694]]\n",
      "\n",
      "W2 (hidden1 -> hidden2):\n",
      "[[-0.00601707  0.01852278 -0.00013497 -0.01057711  0.00822545 -0.01220844]\n",
      " [ 0.00208864 -0.0195967  -0.01328186  0.00196861  0.00738467  0.00171368]\n",
      " [-0.00115648 -0.00301104 -0.01478522 -0.00719844 -0.00460639  0.01057122]\n",
      " [ 0.00343618 -0.0176304   0.00324084 -0.00385082 -0.00676922  0.00611676]\n",
      " [ 0.01031     0.0093128  -0.00839218 -0.00309212  0.00331263  0.00975545]\n",
      " [-0.00479174 -0.00185659 -0.01106335 -0.01196207  0.00812526  0.0135624 ]\n",
      " [-0.0007201   0.01003533  0.00361636 -0.0064512   0.00361396  0.01538037]\n",
      " [-0.00035826  0.01564644 -0.02619745  0.00821903  0.00087047 -0.00299007]]\n",
      "\n",
      "W3 (hidden2 -> output):\n",
      "[[ 0.00091761 -0.01987569]\n",
      " [-0.00219672  0.00357113]\n",
      " [ 0.01477894 -0.0051827 ]\n",
      " [-0.00808494 -0.00501757]\n",
      " [ 0.00915402  0.00328751]\n",
      " [-0.0052976   0.00513267]]\n",
      "\n",
      "\n",
      "After iteration 1:\n",
      "Error: 0.110670\n",
      "\n",
      "Updated W1:\n",
      "[[-0.01724918 -0.00562287 -0.01012827  0.00314246 -0.00908023 -0.01412301\n",
      "   0.01465649 -0.00225771]\n",
      " [ 0.00067528 -0.0142475  -0.0054439   0.00110925 -0.01150995  0.00375692\n",
      "  -0.0060064  -0.00291705]]\n",
      "\n",
      "Updated W2:\n",
      "[[-0.00601595  0.01852363 -0.00014221 -0.01057252  0.00822045 -0.0122061 ]\n",
      " [ 0.00208968 -0.01959583 -0.01328918  0.00197322  0.00737963  0.00171605]\n",
      " [-0.0011554  -0.00301017 -0.01479249 -0.00719385 -0.0046114   0.01057357]\n",
      " [ 0.00343727 -0.01762954  0.00323356 -0.00384622 -0.00677424  0.00611911]\n",
      " [ 0.01031106  0.00931367 -0.00839947 -0.00308752  0.00330761  0.00975781]\n",
      " [-0.00479062 -0.00185574 -0.01107058 -0.01195748  0.00812026  0.01356473]\n",
      " [-0.00071906  0.0100362   0.00360904 -0.00644659  0.00360892  0.01538274]\n",
      " [-0.00035718  0.0156473  -0.02620473  0.00822362  0.00086545 -0.00298772]]\n",
      "\n",
      "Updated W3:\n",
      "[[-0.00116338 -0.02019039]\n",
      " [-0.00428213  0.0032557 ]\n",
      " [ 0.01273428 -0.00549197]\n",
      " [-0.01014734 -0.00532947]\n",
      " [ 0.00706405  0.00297142]\n",
      " [-0.00739894  0.00481491]]\n",
      "\n",
      "\n",
      "After iteration 2:\n",
      "Error: 0.110231\n",
      "\n",
      "Updated W1:\n",
      "[[-0.01724919 -0.00562286 -0.01012824  0.00314245 -0.00908022 -0.01412299\n",
      "   0.01465651 -0.00225765]\n",
      " [ 0.00067529 -0.01424751 -0.00544397  0.00110928 -0.01150998  0.00375686\n",
      "  -0.00600643 -0.00291716]]\n",
      "\n",
      "Updated W2:\n",
      "[[-0.00601377  0.01852556 -0.00014827 -0.01056693  0.00821661 -0.01220271]\n",
      " [ 0.0020918  -0.01959387 -0.0132953   0.00197884  0.00737578  0.00171949]\n",
      " [-0.00115325 -0.00300823 -0.01479859 -0.00718824 -0.00461525  0.01057699]\n",
      " [ 0.00343943 -0.0176276   0.00322747 -0.00384062 -0.00677808  0.00612253]\n",
      " [ 0.01031319  0.00931562 -0.00840559 -0.00308191  0.00330376  0.00976124]\n",
      " [-0.00478844 -0.00185381 -0.01107664 -0.01195189  0.00811642  0.01356812]\n",
      " [-0.00071693  0.01003816  0.0036029  -0.00644097  0.00360506  0.01538618]\n",
      " [-0.00035503  0.01564924 -0.02621083  0.00822923  0.0008616  -0.0029843 ]]\n",
      "\n",
      "Updated W3:\n",
      "[[-0.00321189 -0.02050017]\n",
      " [-0.00633498  0.00294519]\n",
      " [ 0.01072159 -0.0057964 ]\n",
      " [-0.01217758 -0.0056365 ]\n",
      " [ 0.00500673  0.00266027]\n",
      " [-0.00946748  0.00450211]]\n",
      "\n",
      "\n",
      "Predict for the first sample:\n",
      "Input: [[ 0.49671415 -0.1382643 ]]\n",
      "Prediction: [[0.49598202 0.49698449]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "class MultiLayerPerceptron:\n",
    "    def __init__(self, input_size=2, hidden1_size=8, hidden2_size=6, output_size=2, learning_rate=0.1):\n",
    "        self.input_size = input_size\n",
    "        self.hidden1_size = hidden1_size\n",
    "        self.hidden2_size = hidden2_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Initialize weights and biases with random values\n",
    "        # Input to first hidden layer\n",
    "        self.w1 = np.random.randn(input_size, hidden1_size) * 0.01\n",
    "        self.b1 = np.zeros((1, hidden1_size))    \n",
    "        \n",
    "        # First hidden layer to second hidden layer\n",
    "        self.w2 = np.random.randn(hidden1_size, hidden2_size) * 0.01\n",
    "        self.b2 = np.zeros((1, hidden2_size))\n",
    "        \n",
    "        # Second hidden layer to output\n",
    "        self.w3 = np.random.randn(hidden2_size, output_size) * 0.01\n",
    "        self.b3 = np.zeros((1, output_size))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Forward pass through the network\n",
    "        self.X = X\n",
    "        \n",
    "        # Input to first hidden layer\n",
    "        self.z1 = np.dot(X, self.w1) + self.b1\n",
    "        self.a1 = sigmoid(self.z1)\n",
    "        \n",
    "        # First hidden layer to second hidden layer\n",
    "        self.z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        self.a2 = sigmoid(self.z2)\n",
    "        \n",
    "        # Second hidden layer to output\n",
    "        self.z3 = np.dot(self.a2, self.w3) + self.b3\n",
    "        self.output = sigmoid(self.z3)\n",
    "        \n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, y):\n",
    "        # Backward pass - backpropagation\n",
    "        m = self.X.shape[0]  # Number of training examples\n",
    "        \n",
    "        # Calculate the squared error\n",
    "        error = self.output - y\n",
    "        squared_error = np.sum(error**2) / (2 * m)\n",
    "        \n",
    "        # Compute gradients for output layer\n",
    "        delta3 = error * sigmoid_derivative(self.output)\n",
    "        dw3 = np.dot(self.a2.T, delta3) / m\n",
    "        db3 = np.sum(delta3, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Compute gradients for second hidden layer\n",
    "        delta2 = np.dot(delta3, self.w3.T) * sigmoid_derivative(self.a2)\n",
    "        dw2 = np.dot(self.a1.T, delta2) / m\n",
    "        db2 = np.sum(delta2, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Compute gradients for first hidden layer\n",
    "        delta1 = np.dot(delta2, self.w2.T) * sigmoid_derivative(self.a1)\n",
    "        dw1 = np.dot(self.X.T, delta1) / m\n",
    "        db1 = np.sum(delta1, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Store gradients\n",
    "        self.dw1, self.db1 = dw1, db1\n",
    "        self.dw2, self.db2 = dw2, db2\n",
    "        self.dw3, self.db3 = dw3, db3\n",
    "        \n",
    "        return squared_error\n",
    "    \n",
    "    def update_weights(self):\n",
    "        # Update weights using gradient descent\n",
    "        self.w1 -= self.learning_rate * self.dw1\n",
    "        self.b1 -= self.learning_rate * self.db1\n",
    "        \n",
    "        self.w2 -= self.learning_rate * self.dw2\n",
    "        self.b2 -= self.learning_rate * self.db2\n",
    "        \n",
    "        self.w3 -= self.learning_rate * self.dw3\n",
    "        self.b3 -= self.learning_rate * self.db3\n",
    "    \n",
    "    def train_iteration(self, X, y):\n",
    "        # One iteration of training\n",
    "        self.forward(X)\n",
    "        error = self.backward(y)\n",
    "        self.update_weights()\n",
    "        return error\n",
    "\n",
    "\n",
    "# Generate sample data for demonstration\n",
    "np.random.seed(42)  # For reproducibility\n",
    "X = np.random.randn(4, 2)  # 4 examples, 2 features each\n",
    "y = np.random.rand(4, 2)   # 4 examples, 2 outputs each\n",
    "\n",
    "# Create and train the MLP\n",
    "mlp = MultiLayerPerceptron(input_size=2, hidden1_size=8, hidden2_size=6, output_size=2)\n",
    "\n",
    "# Print initial weights\n",
    "print(\"Initial weights:\")\n",
    "print(\"W1 (input -> hidden1):\")\n",
    "print(mlp.w1)\n",
    "print(\"\\nW2 (hidden1 -> hidden2):\")\n",
    "print(mlp.w2)\n",
    "print(\"\\nW3 (hidden2 -> output):\")\n",
    "print(mlp.w3)\n",
    "\n",
    "# First iteration\n",
    "error1 = mlp.train_iteration(X, y)\n",
    "print(\"\\n\\nAfter iteration 1:\")\n",
    "print(f\"Error: {error1:.6f}\")\n",
    "print(\"\\nUpdated W1:\")\n",
    "print(mlp.w1)\n",
    "print(\"\\nUpdated W2:\")\n",
    "print(mlp.w2)\n",
    "print(\"\\nUpdated W3:\")\n",
    "print(mlp.w3)\n",
    "\n",
    "# Second iteration\n",
    "error2 = mlp.train_iteration(X, y)\n",
    "print(\"\\n\\nAfter iteration 2:\")\n",
    "print(f\"Error: {error2:.6f}\")\n",
    "print(\"\\nUpdated W1:\")\n",
    "print(mlp.w1)\n",
    "print(\"\\nUpdated W2:\")\n",
    "print(mlp.w2)\n",
    "print(\"\\nUpdated W3:\")\n",
    "print(mlp.w3)\n",
    "\n",
    "# Demonstrate forward pass\n",
    "print(\"\\n\\nPredict for the first sample:\")\n",
    "sample = X[0:1]  # First sample\n",
    "prediction = mlp.forward(sample)\n",
    "print(f\"Input: {sample}\")\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
